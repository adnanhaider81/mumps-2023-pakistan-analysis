# Snakemake pipeline for MuV genotype G analysis
# Requires NCBI_EMAIL env var for Entrez steps

import yaml, os
cfg = yaml.safe_load(open("config/config.yaml"))

SAMPLES = [x.get("sample","MuV_001") for x in cfg.get("pairs", [{"sample":"MuV_001","r1":"data-private/MuV_001_R1.fastq.gz","r2":"data-private/MuV_001_R2.fastq.gz"}])]
META = {x.get("sample","MuV_001"): x for x in cfg.get("pairs", [])}
if not META:
    META = {"MuV_001": {"r1":"data-private/MuV_001_R1.fastq.gz","r2":"data-private/MuV_001_R2.fastq.gz"}}

THREADS = cfg["params"]["threads"]
MAX_HITS = cfg["params"]["max_blast_hits"]
MODEL_SH = cfg["params"]["iqtree_model_sh"]
MODEL_WG = cfg["params"]["iqtree_model_wg"]
BOOT = cfg["params"]["bootstrap"]
USE_MF = cfg["params"].get("use_model_finder", False)

rule all:
    input:
        expand("results/consensus/{s}.fa", s=SAMPLES),
        "results/consensus/all_consensus.fasta",
        "results/aln/wg_alignment.fasta",
        "results/iqtree/wg.treefile",
        expand("results/sh/{s}.sh.fa", s=SAMPLES),
        "results/sh/sh_alignment.fasta",
        "results/iqtree/sh.treefile",
        expand("results/mutations/{s}_hnf.tsv", s=SAMPLES),
        expand("results/mutations/{s}_sh.tsv", s=SAMPLES)

rule trim:
    input:
        r1=lambda w: META[w.s]["r1"],
        r2=lambda w: META[w.s]["r2"]
    output:
        r1="work/{s}.R1.trim.fastq.gz",
        r2="work/{s}.R2.trim.fastq.gz"
    params:
        adapters=cfg["params"]["trim_adapters"]
    threads: THREADS
    shell:
        "trimmomatic PE -threads {threads} {input.r1} {input.r2} "
        "{output.r1} /dev/null {output.r2} /dev/null "
        "ILLUMINACLIP:{params.adapters}:2:30:10 LEADING:3 TRAILING:3 SLIDINGWINDOW:4:30 MINLEN:50"

rule assemble_spades:
    input:
        r1="work/{s}.R1.trim.fastq.gz",
        r2="work/{s}.R2.trim.fastq.gz"
    output:
        contigs="results/spades/{s}/contigs.fasta"
    threads: THREADS
    shell:
        "spades.py -1 {input.r1} -2 {input.r2} -o results/spades/{wildcards.s}"

rule contig_qc:
    input:
        contigs="results/spades/{s}/contigs.fasta"
    output:
        tsv="results/spades/{s}/contigs.qc.tsv"
    shell:
        "python analysis/scripts/contig_qc.py --in {input.contigs} --out_tsv {output.tsv}"

rule blast_contigs:
    input:
        contigs="results/spades/{s}/contigs.fasta"
    output:
        tsv="results/spades/{s}/contigs.blast.tsv"
    params:
        max_hits=MAX_HITS
    shell:
        "python analysis/scripts/blast_closest.py --in {input.contigs} --max_hits {params.max_hits} --out_tsv {output.tsv}"

rule preferred_list:
    output:
        pref="refs/genotype_g_pref.txt"
    run:
        with open(output.pref, "w") as f:
            for acc in cfg["reference_preference"]["genotype_g_pref"]:
                f.write(acc + "\n")

rule pick_ref:
    input:
        blast="results/spades/{s}/contigs.blast.tsv",
        pref="refs/genotype_g_pref.txt"
    output:
        acc="refs/{s}.ref.txt"
    shell:
        "python analysis/scripts/pick_best_ref.py --blast_tsv {input.blast} --preferred {input.pref} --out_accession {output.acc}"

rule fetch_ref:
    input:
        acc="refs/{s}.ref.txt"
    output:
        fa="refs/{s}.ref.fasta"
    shell:
        "python analysis/scripts/fetch_genbank_single.py --acc $(cat {input.acc}) --out_fasta {output.fa}"

rule map_bwa:
    input:
        r1="work/{s}.R1.trim.fastq.gz",
        r2="work/{s}.R2.trim.fastq.gz",
        ref="refs/{s}.ref.fasta"
    output:
        bam="work/{s}.sorted.bam"
    threads: THREADS
    shell:
        "bwa index {input.ref} && "
        "bwa mem -t {threads} {input.ref} {input.r1} {input.r2} | samtools sort -@ {threads} -o {output.bam} && "
        "picard MarkDuplicates I={output.bam} O=work/{wildcards.s}.dedup.bam M=work/{wildcards.s}.dupmetrics.txt VALIDATION_STRINGENCY=SILENT REMOVE_SEQUENCING_DUPLICATES=false && "
        "samtools index work/{wildcards.s}.dedup.bam"

rule depth_mask_call_consensus:
    input:
        bam="work/{s}.dedup.bam",
        ref="refs/{s}.ref.fasta"
    output:
        depth="work/{s}.depth.txt",
        mask="work/{s}.mask.bed",
        vcf="work/{s}.variants.vcf.gz",
        cons="results/consensus/{s}.fa"
    params:
        min_dp=cfg["params"]["min_depth_consensus"]
    threads: THREADS
    shell:
        "samtools depth -a {input.bam} > {output.depth} && "
        "awk -v OFS='\\t' -v MIN={params.min_dp} '{ if ($3<MIN) print $1, $2-1, $2 }' {output.depth} > {output.mask} && "
        "bcftools mpileup -Ou -f {input.ref} {input.bam} | bcftools call -mv -Oz -o {output.vcf} && bcftools index {output.vcf} && "
        "bcftools consensus -f {input.ref} -m {output.mask} {output.vcf} > {output.cons}"

rule combine_consensus:
    input:
        expand("results/consensus/{s}.fa", s=SAMPLES)
    output:
        "results/consensus/all_consensus.fasta"
    shell:
        "cat {input} > {output}"

rule fetch_context_wg:
    output:
        "results/refs/context_wg.fasta"
    run:
        with open("config/context_wg.txt", "w") as f:
            for acc in cfg["context_wg_acc"]:
                f.write(acc + "\n")
        shell("python analysis/scripts/fetch_genbank.py --acc config/context_wg.txt --out_fasta {output}")

rule align_wg:
    input:
        cons="results/consensus/all_consensus.fasta",
        ctx="results/refs/context_wg.fasta"
    output:
        "results/aln/wg_alignment.fasta"
    shell:
        "mkdir -p results/aln && "
        "cat {input.cons} {input.ctx} > results/aln/wg_input.fasta && "
        "mafft --auto results/aln/wg_input.fasta > {output}"

rule iqtree_wg:
    input:
        aln="results/aln/wg_alignment.fasta"
    output:
        tree="results/iqtree/wg.treefile"
    threads: 2
    params:
        mf=" -m MFP" if USE_MF else "",
        model=MODEL_WG,
        bb=BOOT
    shell:
        "mkdir -p results/iqtree && "
        "iqtree -s {input.aln} {params.mf} -m {params.model} -bb {params.bb} -nt {threads} -pre results/iqtree/wg"

rule extract_sh:
    input:
        cons="results/consensus/{s}.fa"
    output:
        sh="results/sh/{s}.sh.fa"
    params:
        ref="AF280799.1"
    shell:
        "python analysis/scripts/extract_sh_by_alignment.py --ref_acc {params.ref} --sample {input.cons} --out_fa {output.sh}"

rule combine_sh:
    input:
        expand("results/sh/{s}.sh.fa", s=SAMPLES)
    output:
        "results/sh/all_sh.fasta"
    run:
        with open(output[0], "w") as out:
            for i in input:
                out.write(open(i).read())
        # Optionally add Sanger SH
        import yaml, os
        cfg = yaml.safe_load(open("config/config.yaml"))
        sh_fa = cfg.get("sh_fasta", None)
        if sh_fa and os.path.exists(sh_fa):
            with open(output[0], "a") as out:
                out.write(open(sh_fa).read())

rule fetch_context_sh:
    output:
        "results/refs/context_sh.fasta"
    run:
        with open("config/context_sh.txt", "w") as f:
            for acc in cfg["context_sh_acc"]:
                f.write(acc + "\n")
        shell("python analysis/scripts/fetch_genbank.py --acc config/context_sh.txt --out_fasta {output}")

rule align_sh:
    input:
        sh="results/sh/all_sh.fasta",
        ctx="results/refs/context_sh.fasta"
    output:
        "results/sh/sh_alignment.fasta"
    shell:
        "cat {input.sh} {input.ctx} > results/sh/sh_input.fasta && "
        "mafft --auto results/sh/sh_input.fasta > {output}"

rule iqtree_sh:
    input:
        aln="results/sh/sh_alignment.fasta"
    output:
        tree="results/iqtree/sh.treefile"
    threads: 2
    params:
        mf=" -m MFP" if USE_MF else "",
        model=MODEL_SH,
        bb=BOOT
    shell:
        "mkdir -p results/iqtree && "
        "iqtree -s {input.aln} {params.mf} -m {params.model} -bb {params.bb} -nt {threads} -pre results/iqtree/sh"

rule hn_f_mut:
    input:
        cons="results/consensus/{s}.fa"
    output:
        tsv="results/mutations/{s}_hnf.tsv"
    params:
        ref="ON148331.1"
    shell:
        "python analysis/scripts/hn_f_mutations.py --ref_acc {params.ref} --sample {input.cons} --out_tsv {output.tsv}"

rule sh_muts:
    input:
        sh="results/sh/{s}.sh.fa"
    output:
        tsv="results/mutations/{s}_sh.tsv"
    shell:
        "python analysis/scripts/sh_mutation_table.py --sample_sh {input.sh} --out_tsv {output.tsv}"
